{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d713418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from sklweka.classifiers import WekaEstimator\n",
    "from sklweka.dataset import to_nominal_labels\n",
    "\n",
    "import sklweka.jvm as jvm\n",
    "jvm.start(packages=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828c74a",
   "metadata": {},
   "source": [
    "# Use Case 1: Patient Triage in the Emergency Room"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0e840",
   "metadata": {},
   "source": [
    "This notebook is dedicated to the analysis of datasets for patient triage in emergency departments.\n",
    "\n",
    "In this notebook, students will be allocated to load a synthetic dataset of false patients, to analyse them with statistics and or machine learning methodes, and to apply pre/post treatements if they want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da35b67",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292f1eb",
   "metadata": {},
   "source": [
    "To illustrate we’ll use a dataset containing the following variables:\n",
    "\n",
    "| Variable                  | Description                                                   |\n",
    "|---------------------------|---------------------------------------------------------------|\n",
    "| Age                       | Age of the patient (in years)                                 |\n",
    "| BMI                       | Body Mass Index (BMI) of the patient (in Kg/m²)               |\n",
    "| Gender                    | Gender of the patient (M/F/O/U)                               |\n",
    "| Chief_Complaint           | Reason for the patient's visit to the emergency department    |\n",
    "| Chief_Complaint_Severity  | Severity of the patient’s chief complaint                     |\n",
    "| Stress_Level              | General state of the patient according to the clinician       |\n",
    "| Dolor_Degree              | Dolor degree self-estimated by the patient (0-4)              |\n",
    "| D_Blood_Pressure          | Diastolic blood pressure of the patient (in mm Hg)            |\n",
    "| S_Blood_Pressure          | Systolic blood pressure of the patient (in mm Hg)             |\n",
    "| Heart_Rate                | Heart rate of the patient (in beats per minute)               |\n",
    "| Respiratory_Rate          | Respiratory rate of the patient (in breaths per minute)       |\n",
    "| Triage_Priority           | The triage priority assigned to the patient (0-10)            |\n",
    "\n",
    "To use this dataset, we first need to load it from the file **UC1-dataset.csv** using the *read_csv* function from the *pandas* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380302bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UC-dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ed3f6",
   "metadata": {},
   "source": [
    "We can also summarize the values of the different variables using the *describe* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940a02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdcd57",
   "metadata": {},
   "source": [
    "## Pre-analyzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc0730",
   "metadata": {},
   "source": [
    "Now we have loaded our dataset, we can compute some statistics to analyze it before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab91782",
   "metadata": {},
   "source": [
    "### Variables distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcefcb",
   "metadata": {},
   "source": [
    "First, let’s compute the distribution of variables’ values in our dataset.\n",
    "\n",
    "For example, with the age of patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b439c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df[\"Age\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbaf7c",
   "metadata": {},
   "source": [
    "We can observe that a majority patient coming at emergency services are between 50 and 80 years old. Patients between 20 and 40 years old are underrepresented.\n",
    "\n",
    "You can perform additionnal analyzes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5123f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed740db",
   "metadata": {},
   "source": [
    "### Correlation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96bc8f9",
   "metadata": {},
   "source": [
    "We can also compute a correlation matrice to detect if some variables are correlated (positively or negatively).\n",
    "\n",
    "To do so, we use the *corr* function of *pandas* on our dataset (we also use the *factorize* function for non-numerical variables).\n",
    "\n",
    "We obtain then a correlation matrice with, for each cell, a correlation metric between -1 and 1. Close to 1 the two variables are positively correlated, close to -1 the two variables are negatively correlated, close to 0 the two variables are not correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.apply(lambda x: x.factorize()[0]).corr()\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723ceec",
   "metadata": {},
   "source": [
    "We can also plot this correlation matrice as a heatmap using the *heatmap* function from the *seaborn* package to observe correlations between variables more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad723b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_df, cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae3066",
   "metadata": {},
   "source": [
    "We can observe that variables *Chief_Complaint* and *Chief_Complaint_Severity* are lightly positively correlated, as well as *D_Blood_Pressure* and *S_Blood_Pressure*. Which makes senses.\n",
    "\n",
    "What do you also observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c417e",
   "metadata": {},
   "source": [
    "*add your observations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799453d8",
   "metadata": {},
   "source": [
    "### Additionnal pre-analyzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed19c7",
   "metadata": {},
   "source": [
    "If you want to made additionnal pre-analyzes, feel free to do them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dde55c",
   "metadata": {},
   "source": [
    "## Pre-processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7d981",
   "metadata": {},
   "source": [
    "Before training a classifier, we need to split our dataset into a training dataset (90% of the original dataset) and a test dataset (the 10% left), by using the *train_test_split* function of the *scikit-learn* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Triage_Priority\", axis=1)\n",
    "Y = df[\"Triage_Priority\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=SEED)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5923dd34",
   "metadata": {},
   "source": [
    "If you want, it’s also possible to perform some pre-processes on the dataset.\n",
    "\n",
    "For example, you can do data augmentation using the [SMOTENC](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#smotenc) algorithm, a variant of the [SMOTE](https://www.jair.org/index.php/jair/article/view/10302) algorithm for datasets with mixed numerical and categorical variables, which is available in the [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library.\n",
    "\n",
    "**n.b**: be careful to resample only you training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[2, 3, 4, 6]\n",
    "oversampler = SMOTENC(categorical_features=categorical_features, random_state=SEED)\n",
    "resampled_X_train, resampled_Y_train = oversampler.fit_resample(X_train, Y_train)\n",
    "\n",
    "resampled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310196a",
   "metadata": {},
   "source": [
    "As we can observe above, this method allow us to oversample our dataset with additionnal data corresponding to underrepresented classes.\n",
    "\n",
    "For example, if we compare classes before and after resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebdcd46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(Y_train)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(resampled_Y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebbfc8",
   "metadata": {},
   "source": [
    "You can perform other from [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn/wiki) or [scikit-learn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#standardscaler) for under-sampling or over-sampling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83baec2b",
   "metadata": {},
   "source": [
    "## Build your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6376c5",
   "metadata": {},
   "source": [
    "We can now build a classifier by using well known machine learning algorithms.\n",
    "\n",
    "To do so, we’ll use the [scikit-learn](https://scikit-learn.org/stable/) library and the [sklearn-weka-plugin](https://fracpete.github.io/sklearn-weka-plugin/), which contains different algorithms and methods for machine learning.\n",
    "\n",
    "We propose below three well-know machine learning algorithm:\n",
    "\n",
    "* C4.5, a learning algorithm based on decision trees\n",
    "* Naive Bayes, a learning algorithm based on probability thoery and Bayes theorem\n",
    "* Multi-layer Perceptron, a learning algorithm based on artificial neural networks\n",
    "\n",
    "Just uncomment the one you want to use (don’t forget to justify your choice).\n",
    "\n",
    "You can also try other [machine learning algorithms for classification](https://weka.sourceforge.io/doc.dev/weka/classifiers/Classifier.html) available via *weka*, or [machine learning algorithms](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) proposed by *scikit-learn*.\n",
    "\n",
    "Feel free to modify parameters of these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use weka algorithms, we first need to transform classes into nominal labels\n",
    "Y_test = to_nominal_labels(Y_test)\n",
    "resampled_Y_train = to_nominal_labels(resampled_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.5\n",
    "#clf = WekaEstimator(classname=\"weka.classifiers.trees.J48\", options=[\"-M\", \"3\"])\n",
    "\n",
    "# Naive Bayes\n",
    "#clf = WekaEstimator(classname=\"weka.classifiers.bayes.NaiveBayes\", options=[\"-K\"])\n",
    "\n",
    "# Multi-layer Perceptron\n",
    "clf = WekaEstimator(classname=\"weka.classifiers.functions.MultilayerPerceptron\", options=[\"-L\", \"0.1\", \"-N\", \"100\", \"-S\", str(SEED)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58481ef7",
   "metadata": {},
   "source": [
    "Finally, we can train the choosen algorithms, using the *fit* function on the training dataset, to obtain a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27559d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(resampled_X_train, resampled_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe95ebd",
   "metadata": {},
   "source": [
    "## Test your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2307f",
   "metadata": {},
   "source": [
    "Now we have trained a classifier, we must test its performances.\n",
    "\n",
    "To do so, we first need to use the *predict* function on the test dataset to obtain the predictions of the classifier on data it didn’t see yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7507a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd5435",
   "metadata": {},
   "source": [
    "Therefore, we can compute some metrics used in machine learning to evaluate performances of a classifier:\n",
    "\n",
    "* Precision: $\\frac{TP}{TP + FP}$\n",
    "* Recall: $\\frac{TP}{TP + FN}$\n",
    "* f1-score: $2 \\times \\frac{precision \\times recall}{precision + recall}$\n",
    "\n",
    "To do so, we’ll use the *precision_score*, *recall_score*, and *f1_score* of the *scikit-learn* library.\n",
    "\n",
    "**n.b:** because we are in a multi-class classification problem, we have to choose between micro or macro average for these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0003143",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 'micro'\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred, average=avg))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred, average=avg))\n",
    "print(\"F1-score:\", f1_score(Y_test, Y_pred, average=avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38748945",
   "metadata": {},
   "source": [
    "Finally, we can compare the prediction of the classifier with the classification expected by using the *confusion_matrix* function from the *scikit-learn* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb036480",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, Y_pred, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140fcb7",
   "metadata": {},
   "source": [
    "## Use your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319a8f2",
   "metadata": {},
   "source": [
    "Now you have a functional classifier, you can use it to estimate the triage priority of new patient coming at emergency departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patient = pd.DataFrame([{\n",
    "    \"Age\": 52,\n",
    "    \"BMI\": 22,\n",
    "    \"Gender\": \"F\",\n",
    "    \"Race\": \"white\",\n",
    "    \"Chief_Complaint\": \"pain with bright lights\",\n",
    "    \"Chief_Complaint_Severity\": 150,\n",
    "    \"Stress_Level\": \"Very much\",\n",
    "    \"Dolor_Degree\": 4,\n",
    "    \"D_Blood_Pressure\": 90,\n",
    "    \"S_Blood_Pressure\": 120,\n",
    "    \"Heart_Rate\": 90,\n",
    "    \"Respiratory_Rate\": 15\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(new_patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82481c7b",
   "metadata": {},
   "source": [
    "## Bonus: Explain your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9cad3",
   "metadata": {},
   "source": [
    "Finally, it could be interesting to extract explanations from your classifier concerning the reason of a prediction but also concerning its general process of classification.\n",
    "\n",
    "In this section you are totally free to use any things you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477da227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_resampled_X_train = resampled_X_train.to_numpy(copy=True, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ed47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = resampled_Y_train.copy()\n",
    "le= LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "class_names = le.classes_\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = resampled_X_train.columns.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba80169",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[2, 3, 4, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d422d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_names = {}\n",
    "categorical_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    categorical_encoders[feature] = LabelEncoder()\n",
    "    categorical_encoders[feature].fit(np_resampled_X_train[:, feature])\n",
    "    np_resampled_X_train[:, feature] = categorical_encoders[feature].transform(np_resampled_X_train[:, feature])\n",
    "    categorical_names[feature] = categorical_encoders[feature].classes_\n",
    "print(categorical_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e050ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_resampled_X_train = np_resampled_X_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data, categorical_features, categorical_encoders):\n",
    "    np_data = data.to_numpy(copy=True, dtype=str)\n",
    "    for feature in categorical_features:\n",
    "        np_data[:, feature] = categorical_encoders[feature].transform(np_data[:, feature])\n",
    "    return np_data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_data(np_data, feature_names, categorical_features, categorical_encoders):\n",
    "    df_data = pd.DataFrame(np_data, columns = feature_names)\n",
    "    for feature in categorical_features:\n",
    "        le = categorical_encoders[feature]\n",
    "        fe = np_data[:, feature]\n",
    "        tmp = le.inverse_transform(fe.astype(int))\n",
    "        df_data[feature_names[feature]] = tmp\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01137616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_new_patient = encode_data(new_patient, categorical_features, categorical_encoders)\n",
    "encoded_new_patient[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_data(encoded_new_patient, feature_names, categorical_features, categorical_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: clf.predict_proba(decode_data(x, feature_names, categorical_features, categorical_encoders)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3da0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(np_resampled_X_train,\n",
    "                                                   feature_names = feature_names,\n",
    "                                                   class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(encoded_new_patient[0], predict_fn, num_features=6, top_labels=1)\n",
    "exp.show_in_notebook(show_all=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
