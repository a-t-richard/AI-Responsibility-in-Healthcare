{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d713418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklweka.classifiers import WekaEstimator\n",
    "from sklweka.dataset import to_nominal_labels\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import sklweka.jvm as jvm\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may need to run this twice\n",
    "jvm.start(packages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828c74a",
   "metadata": {},
   "source": [
    "# Use Case 1: Patient Triage in the Emergency Room"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0e840",
   "metadata": {},
   "source": [
    "This notebook is dedicated to the analysis of datasets for patient triage in emergency departments.\n",
    "\n",
    "In this notebook, students will be allocated to load a synthetic dataset of false patients, analyze them with statistics and or machine learning methods, and apply pre/post treatments if they want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da35b67",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292f1eb",
   "metadata": {},
   "source": [
    "To illustrate we’ll use a dataset containing the following variables:\n",
    "\n",
    "| Variable                  | Description                                                   |\n",
    "|---------------------------|---------------------------------------------------------------|\n",
    "| Age                       | Age of the patient (in years)                                 |\n",
    "| BMI                       | Body Mass Index (BMI) of the patient (in Kg/m²)               |\n",
    "| Gender                    | Gender of the patient (M/F/O/U)                               |\n",
    "| Race                      | \"race\" of the patient                                         |\n",
    "| Chief_Complaint           | Reason for the patient's visit to the emergency department    |\n",
    "| Chief_Complaint_Severity  | Severity of the patient’s chief complaint                     |\n",
    "| Stress_Level              | General state of the patient according to the clinician       |\n",
    "| Dolor_Degree              | Dolor degree self-estimated by the patient (0-4)              |\n",
    "| D_Blood_Pressure          | Diastolic blood pressure of the patient (in mm Hg)            |\n",
    "| S_Blood_Pressure          | Systolic blood pressure of the patient (in mm Hg)             |\n",
    "| Heart_Rate                | Heart rate of the patient (in beats per minute)               |\n",
    "| Respiratory_Rate          | Respiratory rate of the patient (in breaths per minute)       |\n",
    "| Triage_Priority           | The triage priority assigned to the patient (0-10)            |\n",
    "\n",
    "To use this dataset, we first need to load it from the file **UC1-dataset.csv** using the *read_csv* function from the *pandas* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "380302bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Chief_Complaint</th>\n",
       "      <th>Chief_Complaint_Severity</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Dolor_Degree</th>\n",
       "      <th>D_Blood_Pressure</th>\n",
       "      <th>S_Blood_Pressure</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Respiratory_Rate</th>\n",
       "      <th>Triage_Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>24.4</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>cough</td>\n",
       "      <td>73</td>\n",
       "      <td>A little bit</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>35.3</td>\n",
       "      <td>F</td>\n",
       "      <td>white</td>\n",
       "      <td>fatigue</td>\n",
       "      <td>60</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>24.1</td>\n",
       "      <td>F</td>\n",
       "      <td>white</td>\n",
       "      <td>swollen tonsils</td>\n",
       "      <td>69</td>\n",
       "      <td>Somewhat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>24.9</td>\n",
       "      <td>F</td>\n",
       "      <td>white</td>\n",
       "      <td>shortness of breath</td>\n",
       "      <td>69</td>\n",
       "      <td>A little bit</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>27.5</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>swollen lymph nodes</td>\n",
       "      <td>46</td>\n",
       "      <td>A little bit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17660</th>\n",
       "      <td>73</td>\n",
       "      <td>29.0</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>sinus pain</td>\n",
       "      <td>59</td>\n",
       "      <td>Somewhat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17661</th>\n",
       "      <td>73</td>\n",
       "      <td>29.1</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>sinus pain</td>\n",
       "      <td>59</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17662</th>\n",
       "      <td>74</td>\n",
       "      <td>29.1</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>sinus pain</td>\n",
       "      <td>76</td>\n",
       "      <td>Somewhat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17663</th>\n",
       "      <td>74</td>\n",
       "      <td>29.5</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>sinus pain</td>\n",
       "      <td>76</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17664</th>\n",
       "      <td>78</td>\n",
       "      <td>30.5</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>sinus pain</td>\n",
       "      <td>63</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17665 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age   BMI Gender   Race      Chief_Complaint  Chief_Complaint_Severity   \n",
       "0       19  24.4      M  white                cough                        73  \\\n",
       "1       94  35.3      F  white              fatigue                        60   \n",
       "2       27  24.1      F  white      swollen tonsils                        69   \n",
       "3       29  24.9      F  white  shortness of breath                        69   \n",
       "4       81  27.5      M  white  swollen lymph nodes                        46   \n",
       "...    ...   ...    ...    ...                  ...                       ...   \n",
       "17660   73  29.0      M  white           sinus pain                        59   \n",
       "17661   73  29.1      M  white           sinus pain                        59   \n",
       "17662   74  29.1      M  white           sinus pain                        76   \n",
       "17663   74  29.5      M  white           sinus pain                        76   \n",
       "17664   78  30.5      M  white           sinus pain                        63   \n",
       "\n",
       "       Stress_Level  Dolor_Degree  D_Blood_Pressure  S_Blood_Pressure   \n",
       "0      A little bit           2.0              88.0             127.0  \\\n",
       "1        Not at all           1.0              57.0             114.0   \n",
       "2          Somewhat           3.0              78.0             116.0   \n",
       "3      A little bit           3.0              87.0             113.0   \n",
       "4      A little bit           1.0              85.0             146.0   \n",
       "...             ...           ...               ...               ...   \n",
       "17660      Somewhat           2.0              88.0             102.0   \n",
       "17661    Not at all           0.0              91.0             111.0   \n",
       "17662      Somewhat           3.0              85.0             112.0   \n",
       "17663    Not at all           1.0              88.0             109.0   \n",
       "17664    Not at all           2.0              91.0             109.0   \n",
       "\n",
       "       Heart_Rate  Respiratory_Rate  Triage_Priority  \n",
       "0            83.0              13.0                5  \n",
       "1            78.0              15.0                0  \n",
       "2            82.0              15.0                4  \n",
       "3            96.0              16.0                7  \n",
       "4            99.0              12.0                0  \n",
       "...           ...               ...              ...  \n",
       "17660        75.0              14.0                1  \n",
       "17661        94.0              14.0                0  \n",
       "17662        71.0              15.0                3  \n",
       "17663        68.0              14.0                1  \n",
       "17664        92.0              12.0                1  \n",
       "\n",
       "[17665 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"UC-dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ed3f6",
   "metadata": {},
   "source": [
    "We can also summarize the values of the different variables using the *describe* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940a02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdcd57",
   "metadata": {},
   "source": [
    "## Pre-analyzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc0730",
   "metadata": {},
   "source": [
    "Now we have loaded our dataset, we can compute some statistics to analyze it before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab91782",
   "metadata": {},
   "source": [
    "### Variables distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcefcb",
   "metadata": {},
   "source": [
    "First, let’s compute the distribution of variables’ values in our dataset.\n",
    "\n",
    "For example, with the age of patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b439c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df[\"Age\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbaf7c",
   "metadata": {},
   "source": [
    "We can observe that a majority of patients coming to emergency services are between 50 and 80 years old. Patients between 20 and 40 years old are underrepresented.\n",
    "\n",
    "You can perform additional analyzes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5123f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed740db",
   "metadata": {},
   "source": [
    "### Correlation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96bc8f9",
   "metadata": {},
   "source": [
    "We can also compute a correlation matrice to detect if some variables are correlated (positively or negatively).\n",
    "\n",
    "To do so, we use the *corr* function of *pandas* on our dataset (we also use the *factorize* function for non-numerical variables).\n",
    "\n",
    "Therefore, we obtain a correlation matrice with, for each cell, a correlation metric between -1 and 1. Close to 1, the two variables are positively correlated, close to -1, the two variables are negatively correlated, close to 0, the two variables are not correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.apply(lambda x: x.factorize()[0]).corr()\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723ceec",
   "metadata": {},
   "source": [
    "We can also plot this correlation matrice as a heatmap using the *heatmap* function from the *seaborn* package to observe correlations between variables more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad723b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_df, cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae3066",
   "metadata": {},
   "source": [
    "We can observe that variables *Chief_Complaint* and *Chief_Complaint_Severity* are lightly positively correlated, as well as *D_Blood_Pressure* and *S_Blood_Pressure*. Which makes sense.\n",
    "\n",
    "What do you also observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c417e",
   "metadata": {},
   "source": [
    "*add your observations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799453d8",
   "metadata": {},
   "source": [
    "### Additional pre-analyzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed19c7",
   "metadata": {},
   "source": [
    "If you want to make additional pre-analyzes, feel free to do them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dde55c",
   "metadata": {},
   "source": [
    "## Pre-processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7d981",
   "metadata": {},
   "source": [
    "Before training a classifier, we need to split our dataset into a training dataset (90% of the original dataset) and a test dataset (the 10% left), by using the *train_test_split* function of the *scikit-learn* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Triage_Priority\", axis=1)\n",
    "Y = df[\"Triage_Priority\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=SEED)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5923dd34",
   "metadata": {},
   "source": [
    "If you want, it’s also possible to perform some pre-processes on the dataset.\n",
    "\n",
    "For example, you can do data augmentation using the [SMOTENC](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#smotenc) algorithm, a variant of the [SMOTE](https://www.jair.org/index.php/jair/article/view/10302) algorithm for datasets with mixed numerical and categorical variables, which is available in the [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library.\n",
    "\n",
    "**n.b**: be careful to resample only the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[2, 3, 4, 6]\n",
    "oversampler = SMOTENC(categorical_features=categorical_features, random_state=SEED)\n",
    "resampled_X_train, resampled_Y_train = oversampler.fit_resample(X_train, Y_train)\n",
    "\n",
    "resampled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310196a",
   "metadata": {},
   "source": [
    "As we can observe above, this method allows us to oversample our dataset with additional data corresponding to underrepresented classes.\n",
    "\n",
    "For example, if we compare classes before and after resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebdcd46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(Y_train)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(resampled_Y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebbfc8",
   "metadata": {},
   "source": [
    "You can perform other from [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn/wiki) or [scikit-learn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#standardscaler) for under-sampling or over-sampling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83baec2b",
   "metadata": {},
   "source": [
    "## Build your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6376c5",
   "metadata": {},
   "source": [
    "We can now build a classifier by using well-known Machine Learning algorithms.\n",
    "\n",
    "To do so, we’ll use the [scikit-learn](https://scikit-learn.org/stable/) library and the [sklearn-weka-plugin](https://fracpete.github.io/sklearn-weka-plugin/), which contain different algorithms and methods for machine learning.\n",
    "\n",
    "We propose three well-known ML algorithms:\n",
    "\n",
    "* C4.5, a learning algorithm based on decision trees\n",
    "* Naive Bayes, a learning algorithm based on probability theory and Bayes theorem\n",
    "* Multi-layer Perceptron, a learning algorithm based on artificial neural networks\n",
    "\n",
    "Just uncomment the one you want to use (don’t forget to justify your choice).\n",
    "\n",
    "You can also try other [machine learning algorithms for classification](https://weka.sourceforge.io/doc.dev/weka/classifiers/Classifier.html) available via *weka*, or [machine learning algorithms](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) proposed by *scikit-learn*.\n",
    "\n",
    "Feel free to modify the parameters of these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use weka algorithms, we first need to transform classes into nominal labels\n",
    "Y_test = to_nominal_labels(Y_test)\n",
    "resampled_Y_train = to_nominal_labels(resampled_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.5 (decision trees)\n",
    "clf = WekaEstimator(classname=\"weka.classifiers.trees.J48\", options=[\"-M\", \"3\"])\n",
    "\n",
    "# Naive Bayes\n",
    "#clf = WekaEstimator(classname=\"weka.classifiers.bayes.NaiveBayes\", options=[\"-K\"])\n",
    "\n",
    "# Multi-layer Perceptron\n",
    "#clf = WekaEstimator(classname=\"weka.classifiers.functions.MultilayerPerceptron\", options=[\"-L\", \"0.1\", \"-N\", \"100\", \"-S\", str(SEED)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58481ef7",
   "metadata": {},
   "source": [
    "Finally, we can train the chosen algorithm, using the *fit* function on the training dataset, to obtain a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27559d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(resampled_X_train, resampled_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe95ebd",
   "metadata": {},
   "source": [
    "## Test your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2307f",
   "metadata": {},
   "source": [
    "Now we have trained a classifier, we must test its performance.\n",
    "\n",
    "To do so, we first need to use the *predict* function on the test dataset to obtain the predictions of the classifier on data it didn’t see yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7507a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd5435",
   "metadata": {},
   "source": [
    "Therefore, we can compute some metrics used in machine learning to evaluate the performances of a classifier:\n",
    "\n",
    "* Precision: $\\frac{TP}{TP + FP}$\n",
    "* Recall: $\\frac{TP}{TP + FN}$\n",
    "* f1-score: $2 \\times \\frac{precision \\times recall}{precision + recall}$\n",
    "\n",
    "To do so, we’ll use the *precision_score*, *recall_score*, and *f1_score* of the *scikit-learn* library.\n",
    "\n",
    "**n.b:** because we are in a multi-class classification problem, we have to choose between micro or macro averages for these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0003143",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 'micro'\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred, average=avg))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred, average=avg))\n",
    "print(\"F1-score:\", f1_score(Y_test, Y_pred, average=avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38748945",
   "metadata": {},
   "source": [
    "Finally, we can compare the classifier’s prediction with the classifications expected by using the *confusion_matrix* function from the *scikit-learn* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb036480",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, Y_pred, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140fcb7",
   "metadata": {},
   "source": [
    "## Use your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319a8f2",
   "metadata": {},
   "source": [
    "Now you have a functional classifier, you can use it to estimate the triage priority of new patients coming to emergency departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patient = pd.DataFrame([{\n",
    "    \"Age\": 52,\n",
    "    \"BMI\": 22,\n",
    "    \"Gender\": \"F\",\n",
    "    \"Race\": \"white\",\n",
    "    \"Chief_Complaint\": \"pain with bright lights\",\n",
    "    \"Chief_Complaint_Severity\": 150,\n",
    "    \"Stress_Level\": \"Very much\",\n",
    "    \"Dolor_Degree\": 4,\n",
    "    \"D_Blood_Pressure\": 90,\n",
    "    \"S_Blood_Pressure\": 120,\n",
    "    \"Heart_Rate\": 90,\n",
    "    \"Respiratory_Rate\": 15\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(new_patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82481c7b",
   "metadata": {},
   "source": [
    "## Bonus: Explain your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9cad3",
   "metadata": {},
   "source": [
    "Finally, it could be interesting to extract explanations from your classifier concerning the reason for a prediction and allow end-users to interpret the results of a model.\n",
    "\n",
    "Several methods exist for [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/), such as [Partial Dependence Plot (PDP)](https://hastie.su.domains/ElemStatLearn/) or [Individual Conditional Expectation (ICE)](https://arxiv.org/abs/1309.6392). Both are included in the [*scikit-learn*](https://scikit-learn.org/stable/modules/partial_dependence.html) library.\n",
    "\n",
    "In this section, we’ll use the Local Interpretable Model-agnostic Explanations (LIME) methods proposed by [Ribeiro, Singh, and Guestrin (2016)](https://arxiv.org/abs/1602.04938). This method aims to work on every machine learning model and to provide explanations interpretable by non-computer scientist end-users (by giving the main reason for a prediction).\n",
    "\n",
    "To do so, we’ll use the [*lime*](https://github.com/marcotcr/lime) library developed by the authors.\n",
    "\n",
    "However, this library is based on NumPy arrays and a certain format of data to work, so we’ll need to apply some updates to the dataset.\n",
    "\n",
    "First, we need to parse the dataset from a data frame format to a NumPy array format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb792f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_resampled_X_train = resampled_X_train.to_numpy(copy=True, dtype=str)\n",
    "np_resampled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ca341",
   "metadata": {},
   "source": [
    "Then, because *LIME* will not work with strings, we’ll need to encode the classes of the *Triage_Priority* variable with the *LabelEncoder* of the *scikit-learn* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ed47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = resampled_Y_train.copy()\n",
    "le= LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "class_names = le.classes_ # we keep names of each class for later\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fed6da",
   "metadata": {},
   "source": [
    "We’ll also need to get the names of each feature to run *LIME*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = resampled_X_train.columns.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14187574",
   "metadata": {},
   "source": [
    "Because *LIME* is not able to treat textual values, we’ll also need to encode the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d422d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_names = {}\n",
    "categorical_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    categorical_encoders[feature] = LabelEncoder() # we keep the encoder for later\n",
    "    categorical_encoders[feature].fit(np_resampled_X_train[:, feature]) # setup the encoder\n",
    "    # we take the opportunity to transform our dataset\n",
    "    np_resampled_X_train[:, feature] = categorical_encoders[feature].transform(np_resampled_X_train[:, feature])\n",
    "    categorical_names[feature] = categorical_encoders[feature].classes_ # we keep variables domain for later\n",
    "print(categorical_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9ac4d",
   "metadata": {},
   "source": [
    "Finally, we need to set up all values of the dataset as float to allow *LIME* to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e050ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_resampled_X_train = np_resampled_X_train.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8d9fe",
   "metadata": {},
   "source": [
    "Now, we have to define a way to encode, in the *LIME* format, new data to explain the result of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data, categorical_features, categorical_encoders):\n",
    "    np_data = data.to_numpy(copy=True, dtype=str)\n",
    "    for feature in categorical_features:\n",
    "        np_data[:, feature] = categorical_encoders[feature].transform(np_data[:, feature])\n",
    "    return np_data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_new_patient = encode_data(new_patient, categorical_features, categorical_encoders)\n",
    "encoded_new_patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd281acb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "And, because our model was trained on a dataset in a certain format, we also need to define a way to decode the data given to *LIME*, which we’ll give this data to our model to compute predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2fd03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decode_data(np_data, feature_names, categorical_features, categorical_encoders):\n",
    "    df_data = pd.DataFrame(np_data, columns = feature_names)\n",
    "    for feature in categorical_features:\n",
    "        le = categorical_encoders[feature]\n",
    "        fe = np_data[:, feature]\n",
    "        tmp = le.inverse_transform(fe.astype(int))\n",
    "        df_data[feature_names[feature]] = tmp\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_data(encoded_new_patient, feature_names, categorical_features, categorical_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8ef2c",
   "metadata": {},
   "source": [
    "Therefore, we can parse data given to *LIME* into our dataset’s original format and define the function used by *LIME* to call our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: clf.predict_proba(decode_data(x, feature_names, categorical_features, categorical_encoders)).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f6776",
   "metadata": {},
   "source": [
    "Finally, we can declare *LIME*’s Explainer for tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3da0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(np_resampled_X_train,\n",
    "                                                   feature_names = feature_names,\n",
    "                                                   class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8499110",
   "metadata": {},
   "source": [
    "And, use it to highlight the main reasons that conducted the model’s prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2d459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(encoded_new_patient[0], predict_fn, num_features=5, top_labels=2)\n",
    "exp.show_in_notebook(show_table=False, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216abd35",
   "metadata": {},
   "source": [
    "Now, feel free to modify *LIME*’s parameters or to test other explanation methods for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5205dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
